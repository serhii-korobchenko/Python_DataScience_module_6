{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1a2WXVV8AF8Ra38eKD30_VhmiAySMzo2c","timestamp":1680719405901},{"file_id":"1bECuNk2NMzmtUjKH3U9D89h01WSv38Jg","timestamp":1680708732845},{"file_id":"1G894WS7ltIUTusWWmsCnF_zQhQqZCDOc","timestamp":1680681181214}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Dd6t0uFzuR4X"},"source":["<a id='installing-spark'></a>\n","### Installing Spark"]},{"cell_type":"markdown","metadata":{"id":"6apGVff5h4ca"},"source":["Install Dependencies:\n","\n","\n","1.   Java 8\n","2.   Apache Spark with hadoop and\n","3.   Findspark (used to locate the spark in the system)\n"]},{"cell_type":"code","metadata":{"id":"tt7ZS1_wGgjn","executionInfo":{"status":"ok","timestamp":1680720070418,"user_tz":-60,"elapsed":26450,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n","!pip install -q findspark"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3x0ZRLxjMVr"},"source":["Set Environment Variables:"]},{"cell_type":"code","metadata":{"id":"sdOOq4twHN1K","executionInfo":{"status":"ok","timestamp":1680720070419,"user_tz":-60,"elapsed":25,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ACYMwhgHTYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680720070419,"user_tz":-60,"elapsed":23,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"84e2c2fb-ebbd-4f89-adb0-6c71c1b80d06"},"source":["!ls"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["drive\t     spark-3.1.1-bin-hadoop3.2\t    spark-3.1.1-bin-hadoop3.2.tgz.1\n","sample_data  spark-3.1.1-bin-hadoop3.2.tgz\n"]}]},{"cell_type":"code","metadata":{"id":"KR1zLBk1998Z","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"ok","timestamp":1680720070737,"user_tz":-60,"elapsed":334,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"2525cd91-fdc0-4818-dc7f-75af6c5b00bc"},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n","spark"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fe7bfea91c0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://fc0d187e327d:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"hmIqq6xPK7m7"},"source":["<a id='exploring-the-dataset'></a>\n","## Exploring the Dataset"]},{"cell_type":"code","source":["from random import randint"],"metadata":{"id":"I5GcKftdsLAp","executionInfo":{"status":"ok","timestamp":1680720070740,"user_tz":-60,"elapsed":12,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["rdd = spark.sparkContext.parallelize([randint(10, 100) for _ in range(100)])\n","squares = rdd.map(lambda x: x ** 2)\n","result = squares.reduce(lambda a, b: a + b)"],"metadata":{"id":"GCL9Wwp9sB1I","executionInfo":{"status":"ok","timestamp":1680720070741,"user_tz":-60,"elapsed":12,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YD_MizYcs7iF","executionInfo":{"status":"ok","timestamp":1680720071018,"user_tz":-60,"elapsed":289,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"946851fa-b20c-4982-a978-279d19f0a60c"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["420648"]},"metadata":{},"execution_count":29}]}]}