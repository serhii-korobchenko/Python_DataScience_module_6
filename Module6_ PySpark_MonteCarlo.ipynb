{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1G894WS7ltIUTusWWmsCnF_zQhQqZCDOc","timestamp":1680681181214}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"code","metadata":{"id":"_Jewe_e9CIYa","executionInfo":{"status":"ok","timestamp":1680681242596,"user_tz":-60,"elapsed":8,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"source":["from collections import Counter"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8Y7w6_CCIIT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680681248335,"user_tz":-60,"elapsed":327,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"c69f2296-9412-4ca1-d243-75538dd5b9fb"},"source":["print(\"This is a tutorial!\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["This is a tutorial!\n"]}]},{"cell_type":"code","metadata":{"id":"zdO9sjSdEVnr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680681262936,"user_tz":-60,"elapsed":383,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"8c0215b9-d4d4-4825-cc4a-782c2fe8d591"},"source":["ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"QF9e3lDDEX3I","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1680681292861,"user_tz":-60,"elapsed":309,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"579c55d9-e850-49f9-d318-33a821d662c4"},"source":["pwd"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4wFbBYRUaa76","executionInfo":{"status":"ok","timestamp":1680681359525,"user_tz":-60,"elapsed":25467,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"d2a36cfd-5749-4197-bcaf-3488531c2d3a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dd6t0uFzuR4X"},"source":["<a id='installing-spark'></a>\n","### Installing Spark"]},{"cell_type":"markdown","metadata":{"id":"6apGVff5h4ca"},"source":["Install Dependencies:\n","\n","\n","1.   Java 8\n","2.   Apache Spark with hadoop and\n","3.   Findspark (used to locate the spark in the system)\n"]},{"cell_type":"code","metadata":{"id":"tt7ZS1_wGgjn","executionInfo":{"status":"ok","timestamp":1680681419547,"user_tz":-60,"elapsed":45432,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n","!pip install -q findspark"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3x0ZRLxjMVr"},"source":["Set Environment Variables:"]},{"cell_type":"code","metadata":{"id":"sdOOq4twHN1K","executionInfo":{"status":"ok","timestamp":1680681440017,"user_tz":-60,"elapsed":286,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ACYMwhgHTYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680681453998,"user_tz":-60,"elapsed":368,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"3c8ef059-0c56-43d5-f009-9752b06e9bbb"},"source":["!ls"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data  spark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"]}]},{"cell_type":"code","metadata":{"id":"KR1zLBk1998Z","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"ok","timestamp":1680681502872,"user_tz":-60,"elapsed":7952,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"f187959e-19db-4427-a474-93ce4f6b814e"},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n","spark"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f6d805a5610>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://9a9de9f9d416:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import random\n","\n","def inside(p):\n","    x, y = random.random(), random.random()\n","    return x * x + y * y < 1\n","\n","NUM_SAMPLES = 10 ** 7\n","count = spark.sparkContext.parallelize(range(NUM_SAMPLES)).filter(inside).count()\n","approx_pi = (4.0 * count / NUM_SAMPLES)\n","print(f\"Pi is roughly {approx_pi}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nlyi_IRMbmiT","executionInfo":{"status":"ok","timestamp":1680682143936,"user_tz":-60,"elapsed":9464,"user":{"displayName":"Serhii Korobchenko","userId":"01708571780441783160"}},"outputId":"9f823539-d140-4915-b7b5-ce494f8af026"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Pi is roughly 3.141558\n"]}]}]}